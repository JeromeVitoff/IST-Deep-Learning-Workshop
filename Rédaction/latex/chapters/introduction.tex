% !TEX root = manuscript.tex
\chapter*{Introduction}
Dans un monde de plus en plus numérisé, la reconnaissance automatique de caractères joue un rôle essentiel dans la préservation et l'accessibilité des patrimoines linguistiques et culturels. Les langues utilisant des systèmes d'écriture non latins, comme l'ourdou, représentent un défi particulier pour les technologies de reconnaissance optique de caractères (OCR). L'ourdou, langue officielle du Pakistan et parlée par plus de 170 millions de personnes dans le monde, utilise un alphabet dérivé du perso-arabe avec des caractéristiques calligraphiques complexes et contextuelles qui rendent sa numérisation et son traitement automatique particulièrement difficiles.

Ce mémoire s'inscrit dans le cadre du challenge Kaggle "IST Deep Learning Workshop" sur la reconnaissance de caractères ourdou. L'objectif de cette compétition est de développer un modèle d'apprentissage automatique capable d'identifier correctement des caractères ourdou isolés à partir d'images de dimensions 28×28 pixels. Ce défi implique la classification de 40 classes distinctes de caractères, chacune présentant des variations subtiles de forme et de structure qui nécessitent des approches sophistiquées pour être correctement différenciées.

La reconnaissance de caractères ourdou pose plusieurs défis spécifiques, notamment la similitude entre certains caractères qui ne diffèrent que par de petits détails, la variabilité des styles d'écriture, et la nécessité de capturer des caractéristiques visuelles fines qui distinguent les différentes classes. Ces contraintes exigent des techniques avancées d'intelligence artificielle et de traitement d'images pour atteindre des performances satisfaisantes.

Ce rapport retrace l'évolution méthodique de notre approche, depuis l'implémentation d'un simple Perceptron Multi-Couches (MLP) jusqu'au développement d'un réseau de neurones convolutifs profond. Nous analyserons les performances de chaque modèle, mettant en évidence l'amélioration progressive des résultats et les facteurs techniques qui ont contribué à cette progression. La méthodologie adoptée illustre comment l'adaptation progressive de l'architecture des modèles aux spécificités des données d'image peut conduire à des améliorations significatives des performances.

À travers ce projet, nous démontrerons l'efficacité des techniques modernes d'apprentissage profond pour résoudre des problèmes complexes de vision par ordinateur, et plus particulièrement leur application à la préservation et à l'accessibilité numérique des langues non latines comme l'ourdou. L'évaluation finale de notre approche, avec un score de 99,1\% sur l'ensemble de test de la compétition, valide la pertinence des choix méthodologiques effectués tout au long de ce travail.